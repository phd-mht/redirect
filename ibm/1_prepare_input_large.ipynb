{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19cb5afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import sys\n",
    "from typing import Iterator, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import types as st\n",
    "from pyspark.sql import functions as sf\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "import settings as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf9769f9-0403-4c53-9610-d4f3b85fe6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "STRIP_IDS = True\n",
    "CALCULATE_USD_AMOUNT = True\n",
    "\n",
    "TRX_PARTITIONS = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd40b21f-0f55-40dc-93eb-e449cd1cf5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\n",
    "    sys.version_info.major,\n",
    "    sys.version_info.minor,\n",
    "    sys.version_info.micro,\n",
    ") != (3, 9, 19):\n",
    "    raise EnvironmentError(\n",
    "        \"Only runs efficiently on Python 3.9.19 (Tested on: Conda 24.1.2 | Apple M3 Pro)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b85caee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/04 18:44:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "config = [\n",
    "    (\"spark.driver.memory\", \"32g\"),\n",
    "    (\"spark.worker.memory\", \"32g\"),\n",
    "    (\"spark.driver.maxResultSize\", \"32g\"),\n",
    "    (\"spark.sql.execution.arrow.pyspark.enabled\", \"true\"),\n",
    "]\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"testing\")\n",
    "    .config(conf=SparkConf().setAll(config))\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d9503bf-bc5e-4e10-87d1-dae179e8af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_account = pd.read_csv(s.ACCOUNT_FILE).set_index(\"Account Number\")[\"Entity ID\"].to_dict()\n",
    "data_account_func = sf.udf(lambda x: data_account[x[:9]], st.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a2d4cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(value):\n",
    "    return f\"id-{hash(value)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa090168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000000\n",
      "40000000\n",
      "60000000\n",
      "80000000\n",
      "100000000\n",
      "120000000\n",
      "140000000\n",
      "160000000\n",
      "CPU times: user 2min 4s, sys: 12.2 s, total: 2min 17s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    os.remove(s.STAGED_DATA_CSV_LOCATION)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "\n",
    "mapping = {}\n",
    "with open(s.DATA_FILE) as in_file:\n",
    "    cnt = -1\n",
    "    lines = \"\"\n",
    "    for line in in_file:\n",
    "        cnt += 1\n",
    "        if cnt == 0:\n",
    "            continue\n",
    "        line = line.strip()\n",
    "        line_id = get_id(line)\n",
    "        mapping[line_id] = cnt\n",
    "        lines += f\"{cnt},{line}\\n\"\n",
    "        if not (cnt % 2e7):\n",
    "            print(cnt)\n",
    "            with open(s.STAGED_DATA_CSV_LOCATION, \"a\") as out_file:\n",
    "                out_file.write(lines)\n",
    "                lines = \"\"\n",
    "if lines:\n",
    "    lines = lines.strip()\n",
    "    with open(s.STAGED_DATA_CSV_LOCATION, \"a\") as out_file:\n",
    "        out_file.write(lines)\n",
    "        del lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "467df787",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove(s.STAGED_PATTERNS_CSV_LOCATION)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "lines = \"\"\n",
    "with open(s.PATTERNS_FILE) as in_file:\n",
    "    for line in in_file:\n",
    "        line = line.strip()\n",
    "        if line[:4].isnumeric():\n",
    "            line_id = get_id(line)\n",
    "            cnt = mapping[line_id]\n",
    "            lines += f\"{cnt},{line}\\n\"\n",
    "        else:\n",
    "            lines += f\"{line}\\n\"\n",
    "\n",
    "lines = lines.strip()\n",
    "with open(s.STAGED_PATTERNS_CSV_LOCATION, \"a\") as out_file:\n",
    "    out_file.write(lines)\n",
    "    del lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "304986b5-67dd-431d-b77a-8987b4fcd8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcd1cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = st.StructType(\n",
    "    [\n",
    "        st.StructField(\"transaction_id\", st.IntegerType(), False),\n",
    "        st.StructField(\"timestamp\", st.TimestampType(), False),\n",
    "        st.StructField(\"source_bank\", st.StringType(), False),\n",
    "        st.StructField(\"source\", st.StringType(), False),\n",
    "        st.StructField(\"target_bank\", st.StringType(), False),\n",
    "        st.StructField(\"target\", st.StringType(), False),\n",
    "        st.StructField(\"received_amount\", st.FloatType(), False),\n",
    "        st.StructField(\"receiving_currency\", st.StringType(), False),\n",
    "        st.StructField(\"sent_amount\", st.FloatType(), False),\n",
    "        st.StructField(\"sending_currency\", st.StringType(), False),\n",
    "        st.StructField(\"format\", st.StringType(), False),\n",
    "        st.StructField(\"is_laundering\", st.IntegerType(), False),\n",
    "    ]\n",
    ")\n",
    "columns = [x.name for x in schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c2ee4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(s.STAGED_PATTERNS_CSV_LOCATION, \"r\") as fl:\n",
    "    patterns = fl.read()\n",
    "\n",
    "cases = []\n",
    "case_id = 0\n",
    "for pattern in patterns.split(\"\\n\\n\"):\n",
    "    case_id += 1\n",
    "    if not pattern.strip():\n",
    "        continue\n",
    "    pattern = pattern.split(\"\\n\")\n",
    "    name = pattern.pop(0).split(\" - \")[1]\n",
    "    category, sub_category = name, name\n",
    "    if \": \" in name:\n",
    "        category, sub_category = name.split(\": \")\n",
    "    pattern.pop()\n",
    "    case = pd.DataFrame([x.split(\",\") for x in pattern], columns=columns)\n",
    "    case.loc[:, \"id\"] = case_id\n",
    "    case.loc[:, \"type\"] = category.strip().lower()\n",
    "    case.loc[:, \"sub_type\"] = sub_category.strip().lower()\n",
    "    cases.append(case)\n",
    "cases = pd.concat(cases, ignore_index=True)\n",
    "cases = spark.createDataFrame(cases)\n",
    "cases = cases.withColumn(\"timestamp\", sf.to_timestamp(\"timestamp\", s.TIMESTAMP_FORMAT))\n",
    "cases = cases.select(\"transaction_id\", \"id\", \"type\", \"sub_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45180d75-a337-468b-89e3-38f1b82646f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_MAPPING = {\n",
    "    \"Australian Dollar\": \"aud\",\n",
    "    \"Bitcoin\": \"btc\",\n",
    "    \"Brazil Real\": \"brl\",\n",
    "    \"Canadian Dollar\": \"cad\",\n",
    "    \"Euro\": \"eur\",\n",
    "    \"Mexican Peso\": \"mxn\",\n",
    "    \"Ruble\": \"rub\",\n",
    "    \"Rupee\": \"inr\",\n",
    "    \"Saudi Riyal\": \"sar\",\n",
    "    \"Shekel\": \"ils\",\n",
    "    \"Swiss Franc\": \"chf\",\n",
    "    \"UK Pound\": \"gbp\",\n",
    "    \"US Dollar\": \"usd\",\n",
    "    \"Yen\": \"jpy\",\n",
    "    \"Yuan\": \"cny\",\n",
    "}\n",
    "\n",
    "currency_code = sf.udf(lambda x: CURRENCY_MAPPING[x], st.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edb394c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:==========================================>              (12 + 4) / 16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 591 ms, sys: 203 ms, total: 794 ms\n",
      "Wall time: 6min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "175887982"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data = spark.read.csv(\n",
    "    s.STAGED_DATA_CSV_LOCATION,\n",
    "    header=False,\n",
    "    schema=schema,\n",
    "    timestampFormat=s.TIMESTAMP_FORMAT,\n",
    ")\n",
    "group_by = [\n",
    "    \"timestamp\",\n",
    "    \"source_bank\",\n",
    "    \"source\",\n",
    "    \"target_bank\",\n",
    "    \"target\",\n",
    "    \"receiving_currency\",\n",
    "    \"sending_currency\",\n",
    "    \"format\",\n",
    "]\n",
    "data = data.groupby(group_by).agg(\n",
    "    sf.first(\"transaction_id\").alias(\"transaction_id\"),\n",
    "    sf.collect_set(\"transaction_id\").alias(\"transaction_ids\"),\n",
    "    sf.sum(\"received_amount\").alias(\"received_amount\"),\n",
    "    sf.sum(\"sent_amount\").alias(\"sent_amount\"),\n",
    "    sf.max(\"is_laundering\").alias(\"is_laundering\"),\n",
    ")\n",
    "data = data.withColumn(\n",
    "    \"source_currency\", currency_code(sf.col(\"sending_currency\"))\n",
    ").withColumn(\n",
    "    \"target_currency\",\n",
    "    currency_code(sf.col(\"receiving_currency\")),\n",
    ")\n",
    "data = data.join(cases, on=\"transaction_id\", how=\"left\").repartition(\n",
    "    TRX_PARTITIONS, \"transaction_id\"\n",
    ")\n",
    "data = data.select(\n",
    "    \"transaction_id\",\n",
    "    \"transaction_ids\",\n",
    "    \"timestamp\",\n",
    "    sf.concat(sf.col(\"source\"), sf.lit(\"-\"), sf.col(\"source_currency\")).alias(\"source\"),\n",
    "    sf.concat(sf.col(\"target\"), sf.lit(\"-\"), sf.col(\"target_currency\")).alias(\"target\"),\n",
    "    \"source_bank\",\n",
    "    \"target_bank\",\n",
    "    \"source_currency\",\n",
    "    \"target_currency\",\n",
    "    sf.col(\"sent_amount\").alias(\"source_amount\"),\n",
    "    sf.col(\"received_amount\").alias(\"target_amount\"),\n",
    "    \"format\",\n",
    "    \"is_laundering\",\n",
    ")\n",
    "\n",
    "data = data.withColumn(\"source_entity\", data_account_func(sf.col(\"source\")))\n",
    "data = data.withColumn(\"target_entity\", data_account_func(sf.col(\"target\")))\n",
    "\n",
    "data = data.persist(StorageLevel.DISK_ONLY)\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72d4b7c6-8740-48ac-9314-25ebf3e56862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "178575"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select(sf.explode(\"transaction_ids\")).count() - data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0364dec-3ed8-4213-b7a8-4f6f9eba67dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "cases_data = (\n",
    "    cases.join(\n",
    "        data.withColumnRenamed(\"transaction_id\", \"x\")\n",
    "        .drop(*cases.columns)\n",
    "        .select(sf.explode(\"transaction_ids\").alias(\"transaction_id\"), \"*\"),\n",
    "        on=\"transaction_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .drop(\"is_laundering\", \"transaction_id\", \"transaction_ids\")\n",
    "    .withColumnRenamed(\"x\", \"transaction_id\")\n",
    ")\n",
    "cases_data.toPandas().to_parquet(s.STAGED_CASES_DATA_LOCATION)\n",
    "cases_data = pd.read_parquet(s.STAGED_CASES_DATA_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9958c88-72c6-46c2-89fa-cea3635b7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_rates = {\n",
    "    \"jpy\": np.float32(0.009487665410827868),\n",
    "    \"cny\": np.float32(0.14930721887033868),\n",
    "    \"cad\": np.float32(0.7579775434031815),\n",
    "    \"sar\": np.float32(0.2665884611958837),\n",
    "    \"aud\": np.float32(0.7078143121927827),\n",
    "    \"ils\": np.float32(0.29612081311363503),\n",
    "    \"chf\": np.float32(1.0928961554056371),\n",
    "    \"usd\": np.float32(1.0),\n",
    "    \"eur\": np.float32(1.171783425225877),\n",
    "    \"rub\": np.float32(0.012852809604990688),\n",
    "    \"gbp\": np.float32(1.2916554735187644),\n",
    "    \"btc\": np.float32(11879.132698717296),\n",
    "    \"inr\": np.float32(0.013615817231245796),\n",
    "    \"mxn\": np.float32(0.047296753463246695),\n",
    "    \"brl\": np.float32(0.1771008654705292),\n",
    "}\n",
    "\n",
    "@sf.pandas_udf(st.FloatType())\n",
    "def get_usd_amount(iterator: Iterator[Tuple[pd.Series, pd.Series]]) -> Iterator[pd.Series]:\n",
    "    for a, b in iterator:\n",
    "        yield [currency_rates[x] for x in a] * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8483dd03-18e9-4a29-8f9a-b9e751fcf4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if STRIP_IDS:\n",
    "    data = data.withColumn(\"source\", sf.substring(\"source\", 1, 8))\n",
    "    data = data.withColumn(\"target\", sf.substring(\"target\", 1, 8))\n",
    "if CALCULATE_USD_AMOUNT:\n",
    "    data = data.withColumn(\"amount\", get_usd_amount(\"source_currency\", \"source_amount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fc122b7-70a9-42b4-adab-8c3240df6c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "data.write.parquet(s.STAGED_DATA_LOCATION, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b05f001e-4e47-40a3-9de2-b4a534c05a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.parquet(s.STAGED_DATA_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15609486-de3c-4470-928e-612aa35a08e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "assert data.count() == data.select(\"transaction_id\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4276821f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175887982, 19461, 19461, 2218)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count(), cases_data.shape[0], cases_data[\"transaction_id\"].nunique(), cases_data[\"id\"].nunique()\n",
    "# (179504480, 137936, 137933, 16467)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
